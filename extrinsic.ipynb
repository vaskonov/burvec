{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1653a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.model import *\n",
    "from src.load_data import load_data\n",
    "\n",
    "from pathlib import Path\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b3e3d8-e3cb-4c0f-895e-4589eec2370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "MIN_FREQ = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b3aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [2, 5, 10]\n",
    "vector_sizes = [0, 50, 100, 500]\n",
    "languages = ['bxr']#['bxr', 'myv', 'kv']#['bxr', 'myv', 'kv']\n",
    "methods = ['cbow', 'sg', 'glove']#[-1, 'cbow', 'sg', 'glove', 'pmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe139062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: bxr method: cbow vector_size: 0 window: 2\n",
      "File embeddings/bxr/0/2/cbow doesn't exist\n",
      "language: bxr method: cbow vector_size: 0 window: 5\n",
      "File embeddings/bxr/0/5/cbow doesn't exist\n",
      "language: bxr method: cbow vector_size: 0 window: 10\n",
      "File embeddings/bxr/0/10/cbow doesn't exist\n",
      "language: bxr method: cbow vector_size: 50 window: 2\n",
      "loaded word embeddings embeddings/bxr/50/2/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 47169.85it/s]\n",
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.2833191737042905\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 38369.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.28438961919610584\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 48752.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.2913016831122501\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40909.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.2632733797655026\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 48853.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.22993895658977453\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 49800.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.25905695201402434\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39878.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.306864594920094\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50031.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.26191616709283455\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50997.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.2829851557874693\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50310.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.2816376095739704\n",
      "language: bxr method: cbow vector_size: 50 window: 5\n",
      "loaded word embeddings embeddings/bxr/50/5/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39778.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.2732734854896194\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50228.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.2790946647884159\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50035.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.25028976542368475\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 37905.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.24936369053172774\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 43952.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.2050130753565893\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 51374.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.258521772066408\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39783.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.29235277891160505\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 51021.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.25338046892533916\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40300.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.24517033791507334\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 37530.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.26285637743858103\n",
      "language: bxr method: cbow vector_size: 50 window: 10\n",
      "loaded word embeddings embeddings/bxr/50/10/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39629.40it/s]\n",
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.2931927766593742\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40864.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.3186934678952964\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50760.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.3297623905346947\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 41383.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.32225100434900217\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40104.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.2682638959352373\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50505.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.31007265128834627\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50590.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.32642808954864405\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 35454.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.30066325300098684\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 47620.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.30187508719896344\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39981.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.31953935222110175\n",
      "language: bxr method: cbow vector_size: 100 window: 2\n",
      "loaded word embeddings embeddings/bxr/100/2/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28871.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.3077054950732317\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28947.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.28146917862221976\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29988.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.30893317385976815\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28518.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.29361187983465076\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 30364.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.23811537408538896\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29490.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.2736018449017047\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33317.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.31810873979984877\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28689.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.26195769726631607\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 30164.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.2910221293192062\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33523.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.305674423749468\n",
      "language: bxr method: cbow vector_size: 100 window: 5\n",
      "loaded word embeddings embeddings/bxr/100/5/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 32271.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.28355606114951526\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33767.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.2852147470897443\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33787.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.28751696474177335\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33286.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.28335011993022857\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29595.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.24327307134289727\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 32981.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.2827759755066544\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28988.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.30805505009005757\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33600.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.25629628677195787\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 27649.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.28914052645362\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 31326.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.27161960957285286\n",
      "language: bxr method: cbow vector_size: 100 window: 10\n",
      "loaded word embeddings embeddings/bxr/100/10/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 31771.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.3037020642685057\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33197.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.3248669464774619\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28620.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.341478416296768\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 32439.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.32181703994532185\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 31160.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.25425067841871046\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29941.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.3183990044017076\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29172.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.34098580109512006\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28785.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.2783643560008395\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33300.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.3191415055186918\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28953.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.30943232379550556\n",
      "language: bxr method: cbow vector_size: 500 window: 2\n",
      "loaded word embeddings embeddings/bxr/500/2/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8959.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.33293299856528213\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9152.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.33778744726437054\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9227.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.3273990955492975\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9229.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.32598503691405745\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9140.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.25499601908462416\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9218.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.3078377808737541\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9220.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.33085995276807706\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9029.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.2986804642275747\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9170.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.3062491830858539\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8616.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.3128134572129294\n",
      "language: bxr method: cbow vector_size: 500 window: 5\n",
      "loaded word embeddings embeddings/bxr/500/5/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9198.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.32923733129202554\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9170.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.34771177186591445\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9111.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.363523685502062\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8981.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.32356576534548587\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9033.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.285282652719146\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9095.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.3131061188149138\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9022.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.3505934659172574\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9044.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.3160779175492237\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9261.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.3234584813403056\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9118.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.3137498174937965\n",
      "language: bxr method: cbow vector_size: 500 window: 10\n",
      "loaded word embeddings embeddings/bxr/500/10/cbow\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9192.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.3453691653850501\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9250.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.3566501716480172\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9250.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.3793432561318543\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9056.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.3445498021076846\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9128.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.2923549801805604\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9249.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.3417634834029727\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9199.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.3830347787266067\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9245.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.3526945237756219\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9086.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.3490290102116264\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9050.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.36155239209287743\n",
      "language: bxr method: sg vector_size: 0 window: 2\n",
      "File embeddings/bxr/0/2/sg doesn't exist\n",
      "language: bxr method: sg vector_size: 0 window: 5\n",
      "File embeddings/bxr/0/5/sg doesn't exist\n",
      "language: bxr method: sg vector_size: 0 window: 10\n",
      "File embeddings/bxr/0/10/sg doesn't exist\n",
      "language: bxr method: sg vector_size: 50 window: 2\n",
      "loaded word embeddings embeddings/bxr/50/2/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50086.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.3071406444607525\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40056.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.300376940519673\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 44119.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.32020190662250714\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 49891.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.29104914364827755\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 49925.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.240105263640558\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 38712.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.2860203956636793\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50218.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.33681617490540194\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40868.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.2964810242505454\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50450.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.3083826576497539\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40899.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.28912120882904696\n",
      "language: bxr method: sg vector_size: 50 window: 5\n",
      "loaded word embeddings embeddings/bxr/50/5/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39781.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.30218976211612053\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 49402.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.3140923527998092\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40192.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.31936631478782396\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50551.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.3150339332929324\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 46175.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.23640369827044735\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 50396.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.2832605536340049\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 47920.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.34677525459834335\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 41449.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.27231497890031053\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 51007.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.28792211435149523\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 47939.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.2913653285579111\n",
      "language: bxr method: sg vector_size: 50 window: 10\n",
      "loaded word embeddings embeddings/bxr/50/10/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 37150.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.2748850322729679\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 41201.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.2514211236613247\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 41310.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.2818832946593651\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 38890.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.30045206375274053\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 41731.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.2572016759610265\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39708.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.27535715838378544\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 37792.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.3431085044762028\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 40410.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.2774692380700362\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 39192.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.28060318495680037\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 41387.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.287542112439633\n",
      "language: bxr method: sg vector_size: 100 window: 2\n",
      "loaded word embeddings embeddings/bxr/100/2/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28152.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.36152628684390975\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 25020.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.3411207687966412\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28745.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.35397942007865874\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 30076.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.3038675123812153\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 30358.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.2704779787321039\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33365.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.33000393297781627\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28905.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.36975689138332674\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 32922.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.3354634186464959\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28980.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.33294294252369405\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33314.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.32272893595217483\n",
      "language: bxr method: sg vector_size: 100 window: 5\n",
      "loaded word embeddings embeddings/bxr/100/5/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33057.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.3863765097140561\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 31637.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.3833054805425772\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 27920.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.3728404326350229\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28833.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.33413458269121393\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 32961.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.28855232798020725\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 32900.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.32700875936763757\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29566.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.401214927945358\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29146.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.36405970396648873\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 27521.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.3447074553902679\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 32311.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.36093654376094136\n",
      "language: bxr method: sg vector_size: 100 window: 10\n",
      "loaded word embeddings embeddings/bxr/100/10/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33281.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.3867628102344429\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 28517.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.38847569522158865\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33501.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.37721861208345064\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33149.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.3568393322385885\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33395.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.2915421090689347\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33051.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.3257697534579676\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33315.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.3889370153352774\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 29481.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.3622111978668089\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33331.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.36414935423536404\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 33466.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.3612562890247508\n",
      "language: bxr method: sg vector_size: 500 window: 2\n",
      "loaded word embeddings embeddings/bxr/500/2/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9158.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.39765567551771414\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9242.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.42237689689743274\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9236.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.38906581963524567\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9141.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.39701793462680673\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9182.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.2969385861212023\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8692.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.3637946596884024\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9072.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.42675381984083915\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8946.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.38657762454606953\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8809.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.3849639552015867\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 7279.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.385671084407469\n",
      "language: bxr method: sg vector_size: 500 window: 5\n",
      "loaded word embeddings embeddings/bxr/500/5/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9181.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.428528957613188\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9217.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.426715377254266\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8824.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.41260430620869076\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9158.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.3892605647676272\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9302.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.3297024177342678\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9213.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.365725579397631\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9310.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.4228090153042572\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8959.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.4200324703845426\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8879.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.39848422846358855\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9048.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.41953780451573053\n",
      "language: bxr method: sg vector_size: 500 window: 10\n",
      "loaded word embeddings embeddings/bxr/500/10/sg\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9122.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.42855763352938026\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9185.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.4537579167225739\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9106.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.4213476430532955\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9265.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.4148846049987135\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9254.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.3366954532738893\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9257.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.3753397306470047\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 8943.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.44576933414133296\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9054.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.4457846188049965\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9188.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.39512940510656824\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6124 [00:00<?, ?it/s]Skipping token b'6124' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6124/6124 [00:00<00:00, 9034.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.4259300897572642\n",
      "language: bxr method: glove vector_size: 0 window: 2\n",
      "File embeddings/bxr/0/2/glove doesn't exist\n",
      "language: bxr method: glove vector_size: 0 window: 5\n",
      "File embeddings/bxr/0/5/glove doesn't exist\n",
      "language: bxr method: glove vector_size: 0 window: 10\n",
      "File embeddings/bxr/0/10/glove doesn't exist\n",
      "language: bxr method: glove vector_size: 50 window: 2\n",
      "loaded word embeddings embeddings/bxr/50/2/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 51821.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.35588754299671194\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39741.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.3922738782163197\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 51368.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.36906554025357974\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 41345.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.35383548868943204\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 51651.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.26383099623420025\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 41544.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.332279481636825\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 48222.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.38511372578573916\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 37628.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.3735535994704577\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 37806.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.31488209187766\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 50401.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.3452617978137198\n",
      "language: bxr method: glove vector_size: 50 window: 5\n",
      "loaded word embeddings embeddings/bxr/50/5/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39853.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.33732736157587806\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 43271.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.37213080809069266\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 47038.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.3742937491546326\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 41212.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.3499230640050505\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 40004.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.2849037674324607\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39102.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.33991917900403223\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 41759.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.3736284581385343\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39090.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.33446516511090124\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39323.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.3219701123604072\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 40230.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.37063589843551675\n",
      "language: bxr method: glove vector_size: 50 window: 10\n",
      "loaded word embeddings embeddings/bxr/50/10/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39759.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 50])\n",
      "score: 0.3741457642727528\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39813.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 50])\n",
      "score: 0.3829371857435996\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 40414.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 50])\n",
      "score: 0.38658792654044005\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 42031.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.32626312776556765\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 41747.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 50])\n",
      "score: 0.28789364160072445\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 41489.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 50])\n",
      "score: 0.3232024254602106\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 51293.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 50])\n",
      "score: 0.3884947454020649\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 39631.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 50])\n",
      "score: 0.37868589322584395\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 44082.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 50])\n",
      "score: 0.3271131642499598\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'50']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 42534.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 94,353 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 50])\n",
      "score: 0.360784155401023\n",
      "language: bxr method: glove vector_size: 100 window: 2\n",
      "loaded word embeddings embeddings/bxr/100/2/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 24924.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.39467311311684405\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 33311.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.43935384108864356\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 28638.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.40602478554390625\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29709.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.37745706161524406\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29609.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.2863031882308972\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 34121.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.35627774850934446\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 28730.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.4120968064622683\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 28456.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.3845648283198831\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29943.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.3465132758167744\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29528.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.40480162966439354\n",
      "language: bxr method: glove vector_size: 100 window: 5\n",
      "loaded word embeddings embeddings/bxr/100/5/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 30461.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.398125958322964\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 28875.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.4280305347673376\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29750.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.401660949660548\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 33449.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.3824388056973559\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 30439.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.31123207957008364\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 30169.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.35582832716606183\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 30464.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.42983448888126485\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29239.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.4093634772094628\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29289.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.3779856703701232\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 29534.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.39678587992295417\n",
      "language: bxr method: glove vector_size: 100 window: 10\n",
      "loaded word embeddings embeddings/bxr/100/10/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 31655.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 100])\n",
      "score: 0.42654367791184117\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 27590.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 100])\n",
      "score: 0.45965372949440453\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 28945.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 100])\n",
      "score: 0.4297885739272657\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 34457.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.4006019860774009\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 31429.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 100])\n",
      "score: 0.32865185938497904\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 34033.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 100])\n",
      "score: 0.37814209162601914\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 30334.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 100])\n",
      "score: 0.44880596236604564\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 23745.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 100])\n",
      "score: 0.4201931995024814\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 28947.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 100])\n",
      "score: 0.3695438022337204\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 32472.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 119,953 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 100])\n",
      "score: 0.429049503153179\n",
      "language: bxr method: glove vector_size: 500 window: 2\n",
      "loaded word embeddings embeddings/bxr/500/2/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9076.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.4151134632147946\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9534.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.44386896694841355\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9263.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.43020732215704555\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9572.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.3790876283198778\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9654.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.31085392553731894\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9603.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.371953911826412\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9614.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.43513848683123685\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9555.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.42030319819656015\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9686.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.3939002804888072\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9473.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.43835431913424566\n",
      "language: bxr method: glove vector_size: 500 window: 5\n",
      "loaded word embeddings embeddings/bxr/500/5/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9417.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.4395245744902957\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9707.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.4843514090730584\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9341.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.450459999178191\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9592.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.4413792149774312\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9249.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.34458573452116936\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9587.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.4683480826656789\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9286.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.4774109382969414\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9484.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.5244551818721528\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9357.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.41561213801836705\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9179.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.4562269882490942\n",
      "language: bxr method: glove vector_size: 500 window: 10\n",
      "loaded word embeddings embeddings/bxr/500/10/glove\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9450.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3655\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3655, 500])\n",
      "score: 0.4892389889006683\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9205.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3680\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3680, 500])\n",
      "score: 0.5385702594620597\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9390.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3708\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3708, 500])\n",
      "score: 0.5209211267207198\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9184.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.49399606343605834\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9251.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3689\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3689, 500])\n",
      "score: 0.3577540313814306\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9205.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3693\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3693, 500])\n",
      "score: 0.470886637948992\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 7211.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3660\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3660, 500])\n",
      "score: 0.5515792103498847\n",
      "train_data 772 val_data 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9531.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3672\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3672, 500])\n",
      "score: 0.5257485161162305\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9452.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3666\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3666, 500])\n",
      "score: 0.46979363020727116\n",
      "train_data 773 val_data 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6125 [00:00<?, ?it/s]Skipping token b'6125' with 1-dimensional vector [b'500']; likely a header\n",
      "100%|██████████| 6125/6125 [00:00<00:00, 9551.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 3692\n",
      "Unique tokens in UD_TAG vocabulary: 17\n",
      "The model has 324,753 trainable parameters\n",
      "load pretrained embs\n",
      "embeddings torch.Size([3692, 500])\n",
      "score: 0.472614666542615\n"
     ]
    }
   ],
   "source": [
    "scores_d = {}\n",
    "for language in languages:\n",
    "    data_generator = load_data(language = language, SEED = SEED)\n",
    "    \n",
    "    scores_d[language] = {}\n",
    "    for method in methods:\n",
    "        if method not in scores_d[language]:\n",
    "            scores_d[language][method] = {}\n",
    "        \n",
    "        for vector_size in vector_sizes:\n",
    "            if vector_size not in scores_d[language][method]:\n",
    "                scores_d[language][method][vector_size] = {}\n",
    "                    \n",
    "            for window in windows:            \n",
    "                if window not in scores_d[language][method][vector_size]:\n",
    "                    scores_d[language][method][vector_size][window] = []\n",
    "                \n",
    "                print(\"language:\", language, \"method:\", method, \"vector_size:\", vector_size, \"window:\", window)\n",
    "                if method != -1:\n",
    "                    path = Path(\"./embeddings/\"+language+\"/\"+str(vector_size)+\"/\"+str(window)+\"/\"+method)\n",
    "                    if not path.is_file():\n",
    "                        print(\"File\", path, \"doesn't exist\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(\"loaded word embeddings\", path)\n",
    "                else:\n",
    "                    if vector_size == 0:\n",
    "                        print(\"skipping\")\n",
    "                        continue\n",
    "                \n",
    "                for NUM, TEXT, LEMMA, UD_TAGS, train_data, val_data in data_generator.get_fold_data():\n",
    "                    \n",
    "                    print(\"train_data\", len(train_data.examples), \"val_data\", len(val_data.examples))\n",
    "                    \n",
    "                    if method == -1:\n",
    "                        TEXT.build_vocab(train_data, min_freq = MIN_FREQ)\n",
    "                        emb_size = vector_size\n",
    "                    else:\n",
    "                        !rm -rf /tmp/vec\n",
    "                        _vectors = Vectors(name=path, cache='/tmp/vec')\n",
    "                        TEXT.build_vocab(train_data,\n",
    "                            min_freq = MIN_FREQ,\n",
    "                            vectors = _vectors,\n",
    "                            unk_init = torch.Tensor.normal_\n",
    "                        )\n",
    "                        emb_size = TEXT.vocab.vectors[1].shape[0]\n",
    "                        \n",
    "                        if vector_size !=0:\n",
    "                            assert vector_size==TEXT.vocab.vectors[1].shape[0], \"Different sizes\"\n",
    "                        \n",
    "                    LEMMA.build_vocab(train_data)\n",
    "                    NUM.build_vocab(train_data)\n",
    "                    UD_TAGS.build_vocab(train_data)\n",
    "                    \n",
    "                    print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "                    print(f\"Unique tokens in UD_TAG vocabulary: {len(UD_TAGS.vocab)}\")\n",
    "                    \n",
    "                    train_iterator, val_iterator = data.BucketIterator.splits(\n",
    "                                                        (train_data, val_data),\n",
    "                                                        sort=True,\n",
    "                                                        sort_key=lambda x: len(x.text),\n",
    "                                                        sort_within_batch=False,\n",
    "                                                        batch_size=BATCH_SIZE, \n",
    "                                                        repeat=False,\n",
    "                                                        shuffle=True,\n",
    "                                                        device=device)\n",
    "                    \n",
    "                    pos_score = pos(TEXT, UD_TAGS, train_iterator, val_iterator, emb_size, epochs=30, verbose = False)\n",
    "                    print(\"score:\", pos_score)\n",
    "                    scores_d[language][method][vector_size][window].append(pos_score)\n",
    "                scores_d[language][method][vector_size][window] = np.average(scores_d[language][method][vector_size][window])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "afea1779-d485-413c-bf26-833f13c530f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "словарь 3655\n",
      "не найдено 1329\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for idx, vec in enumerate(TEXT.vocab.vectors):\n",
    "    if vec[0] == 0 and not TEXT.vocab.itos[idx].isdigit():\n",
    "#         print(TEXT.vocab.itos[idx])\n",
    "        count += 1\n",
    "\n",
    "print('словарь', len(TEXT.vocab.vectors))\n",
    "print('не найдено', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "223f321d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi[TEXT.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfa7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(TEXT, UD_TAGS, train_iterator, val_iterator, emb_size, epochs=10, verbose = True):\n",
    "      \n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = emb_size\n",
    "    HIDDEN_DIM = 128\n",
    "    OUTPUT_DIM = len(UD_TAGS.vocab)\n",
    "    N_LAYERS = 1\n",
    "    BIDIRECTIONAL = False\n",
    "    DROPOUT = 0.25\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model = BiLSTMPOSTagger(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT,\n",
    "                        PAD_IDX)\n",
    "    \n",
    "    model.apply(init_weights)\n",
    "    print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "    \n",
    "    if TEXT.vocab.vectors is not None:\n",
    "        print(\"load pretrained embs\")\n",
    "        pretrained_embeddings = TEXT.vocab.vectors\n",
    "        print('embeddings', pretrained_embeddings.shape)\n",
    "    \n",
    "        model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "        model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    else:\n",
    "        print(\"no loading any pretrained embs\")\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "    \n",
    "        train_loss = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "        valid_loss, valid_acc = evaluate(model, val_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    test_loss, test_acc = evaluate(model, val_iterator, criterion, TAG_PAD_IDX)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc8d635b-8a7c-43a4-8ceb-5f5fa58209b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "& 50  &  0.132 & 0.132 & 0.132 \\\\\n",
      "& 100  &  0.205 & 0.205 & 0.205 \\\\\n",
      "& 500  &  0.484 & 0.484 & 0.484 \\\\\n",
      "cbow\n",
      "& 50  &  0.299 & 0.298 & 0.322 \\\\\n",
      "& 100  &  0.307 & 0.314 & 0.329 \\\\\n",
      "& 500  &  0.332 & 0.347 & 0.362 \\\\\n",
      "sg\n",
      "& 50  &  0.325 & 0.32 & 0.327 \\\\\n",
      "& 100  &  0.349 & 0.369 & 0.378 \\\\\n",
      "& 500  &  0.398 & 0.412 & 0.424 \\\\\n",
      "glove\n",
      "& 50  &  0.361 & 0.362 & 0.371 \\\\\n",
      "& 100  &  0.389 & 0.396 & 0.419 \\\\\n",
      "& 500  &  0.411 & 0.482 & 0.49 \\\\\n",
      "pmi\n",
      "& 50  &  0.402 & 0.417 & 0.467 \\\\\n",
      "& 100  &  0.491 & 0.502 & 0.515 \\\\\n",
      "& 500  &  0.56 & 0.564 & 0.569 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.eval import tabular\n",
    "tabular(scores_d, 'bxr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216cb4d6-38a2-4c11-86d7-afc968eb1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "0\n",
    "& 50  &  0.132 & 0.132 & 0.132 \\\\\n",
    "& 100  &  0.205 & 0.205 & 0.205 \\\\\n",
    "& 500  &  0.484 & 0.484 & 0.484 \\\\\n",
    "cbow\n",
    "& 50  &  0.299 & 0.298 & 0.322 \\\\\n",
    "& 100  &  0.307 & 0.314 & 0.329 \\\\\n",
    "& 500  &  0.332 & 0.347 & 0.362 \\\\\n",
    "sg\n",
    "& 50  &  0.325 & 0.32 & 0.327 \\\\\n",
    "& 100  &  0.349 & 0.369 & 0.378 \\\\\n",
    "& 500  &  0.398 & 0.412 & 0.424 \\\\\n",
    "glove\n",
    "& 50  &  0.361 & 0.362 & 0.371 \\\\\n",
    "& 100  &  0.389 & 0.396 & 0.419 \\\\\n",
    "& 500  &  0.411 & 0.482 & 0.49 \\\\\n",
    "pmi\n",
    "& 50  &  0.402 & 0.417 & 0.467 \\\\\n",
    "& 100  &  0.491 & 0.502 & 0.515 \\\\\n",
    "& 500  &  0.56 & 0.564 & 0.569 \\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9bc497-7c50-4825-bb1c-3e5701e882ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "& 50  &  0.268 & 0.268 & 0.268 \\\\\n",
      "& 100  &  0.353 & 0.353 & 0.353 \\\\\n",
      "& 500  &  0.535 & 0.535 & 0.535 \\\\\n",
      "cbow\n",
      "& 50  &  0.351 & 0.368 & 0.386 \\\\\n",
      "& 100  &  0.367 & 0.382 & 0.407 \\\\\n",
      "& 500  &  0.388 & 0.396 & 0.429 \\\\\n",
      "sg\n",
      "& 50  &  0.392 & 0.388 & 0.377 \\\\\n",
      "& 100  &  0.413 & 0.41 & 0.423 \\\\\n",
      "& 500  &  0.435 & 0.442 & 0.455 \\\\\n",
      "glove\n",
      "& 50  &  0.415 & 0.426 & 0.425 \\\\\n",
      "& 100  &  0.444 & 0.469 & 0.465 \\\\\n",
      "& 500  &  0.472 & 0.491 & 0.508 \\\\\n",
      "pmi\n",
      "& 50  &  0.429 & 0.473 & 0.458 \\\\\n",
      "& 100  &  0.479 & 0.501 & 0.502 \\\\\n",
      "& 500  &  0.539 & 0.541 & 0.55 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.eval import tabular\n",
    "tabular(scores_d, 'myv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa37005b-a0e5-4f53-8685-2c3a0ddb8dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type list doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4b98e7aa5149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/burvec/src/eval.py\u001b[0m in \u001b[0;36mtabular\u001b[0;34m(scores_d, language)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" & \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" & \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\\\\\\\\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/burvec/src/eval.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" & \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" & \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\\\\\\\\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: type list doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "from src.eval import tabular\n",
    "\n",
    "tabular(scores_d, 'kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a8ed6f-1ef6-45c5-bd33-88f3921762cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'bxr': {   'cbow': {   0: {2: [], 5: [], 10: []},\n",
      "                           50: {   2: 0.2744683291756316,\n",
      "                                   5: 0.25693164168470434,\n",
      "                                   10: 0.30907419686316473},\n",
      "                           100: {   2: 0.28801999365118036,\n",
      "                                    5: 0.27907984126493013,\n",
      "                                    10: 0.31124381362186326},\n",
      "                           500: {   2: 0.31355414355458205,\n",
      "                                    5: 0.3266307007840131,\n",
      "                                    10: 0.35063415636628714}},\n",
      "               'glove': {   0: {2: [], 5: [], 10: []},\n",
      "                            50: {   2: 0.3485984142974646,\n",
      "                                    5: 0.3459197563308106,\n",
      "                                    10: 0.35361080296621866},\n",
      "                            100: {   2: 0.3808066278368199,\n",
      "                                     5: 0.38912861715681557,\n",
      "                                     10: 0.40909743856773373},\n",
      "                            500: {   2: 0.40387815026547125,\n",
      "                                     5: 0.450235426134238,\n",
      "                                     10: 0.489110313106593}},\n",
      "               'sg': {   0: {2: [], 5: [], 10: []},\n",
      "                         50: {   2: 0.2975695360190196,\n",
      "                                 5: 0.2968724291309198,\n",
      "                                 10: 0.28299233886338826},\n",
      "                         100: {   2: 0.3321868088316037,\n",
      "                                  5: 0.35631367239937706,\n",
      "                                  10: 0.36031621687671744},\n",
      "                         500: {   2: 0.3850816056482768,\n",
      "                                  5: 0.401340072164379,\n",
      "                                  10: 0.4143196430035019}}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(scores_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84efef57-01e6-4144-8062-344788244866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('extrinsic.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(scores_d, f, sort_keys=False, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d669db-da36-4b63-acd2-e7bcd1c0a9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
