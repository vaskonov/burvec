{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbdd1518-f249-44c7-bf93-6c07118c3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/com/burvec/UD_Buryat-BDT/bxr_bdt-ud-train.conllu\"\n",
    "test_path = \"/home/com/burvec/UD_Buryat-BDT/bxr_bdt-ud-test.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce07e45-80d4-4466-aa73-660a3fb2afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(in_file, lowercase=True, max_example=None):\n",
    "    examples = []\n",
    "    with open(in_file) as f:\n",
    "        word, pos, head, label = [], [], [], []\n",
    "        for line in f.readlines():\n",
    "            sp = line.strip().split('\\t')\n",
    "            if len(sp) == 10:\n",
    "                if '-' not in sp[0]:\n",
    "                    word.append(sp[1].lower() if lowercase else sp[1])\n",
    "                    pos.append(sp[3])\n",
    "                    head.append(int(sp[6]))\n",
    "                    label.append(sp[7])\n",
    "            elif len(word) > 0:\n",
    "                examples.append({'word': word, 'pos': pos, 'head': head, 'label': label})\n",
    "                word, pos, head, label = [], [], [], []\n",
    "                if (max_example is not None) and (len(examples) == max_example):\n",
    "                    break\n",
    "        if len(word) > 0:\n",
    "            examples.append({'word': word, 'pos': pos, 'head': head, 'label': label})\n",
    "    return examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95c9773c-1a68-448c-b74a-724a0311d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_conll(train_path)\n",
    "test = read_conll(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b56cdcd5-312d-49d5-b172-f1a48614f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(we, vocab):\n",
    "    words = []\n",
    "    poss = []\n",
    "    for sen in train:\n",
    "        words.extend(sen['word'])\n",
    "        poss.extend(sen['pos'])\n",
    "    X_train = [we[w] for w in words if w in vocab]\n",
    "    y_train = [poss[i] for i, w in enumerate(words) if w in vocab]\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e07ee32-3902-47d9-8300-2da0352408d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(we, vocab):\n",
    "    words = []\n",
    "    poss = []\n",
    "    for sen in test:\n",
    "        words.extend(sen['word'])\n",
    "        poss.extend(sen['pos'])\n",
    "    X_test = [we[w] for w in words if w in vocab]\n",
    "    y_test = [poss[i] for i, w in enumerate(words) if w in vocab]\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce64e989-907a-4484-ac09-77776b96a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emb(path):\n",
    "    we = {}\n",
    "    with open(path, 'r') as f:\n",
    "        next(f) \n",
    "        for l in f:\n",
    "            sp = l.split()\n",
    "            we[sp[0]] = [float(vec) for vec in sp[1:]]\n",
    "    return we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9acb53d2-c008-4a47-a87b-340f47973a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_test, y_test, test_size=0.85, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb5b94dd-e86b-4ca6-ab78-df490cbe4c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fd967d1-1790-4bee-b28a-997789f3aa27",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0e4ce13be808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# clf = SVC(C=100, random_state=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1347\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    639\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "# clf = SVC(C=100, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f825a13d-ce82-45ed-96a4-ade41185c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.53      0.52      0.53       328\n",
      "         ADP       0.76      0.67      0.71       106\n",
      "         ADV       0.46      0.58      0.51       281\n",
      "         AUX       0.70      0.62      0.66        85\n",
      "       CCONJ       0.70      0.84      0.77        37\n",
      "         DET       0.75      0.62      0.68        96\n",
      "        INTJ       0.00      0.00      0.00         2\n",
      "        NOUN       0.71      0.64      0.67       991\n",
      "         NUM       0.64      0.67      0.65        81\n",
      "        PART       1.00      0.71      0.83        68\n",
      "        PRON       0.71      0.24      0.36        71\n",
      "       PROPN       0.50      0.50      0.50       141\n",
      "        VERB       0.38      0.53      0.44       303\n",
      "\n",
      "    accuracy                           0.59      2590\n",
      "   macro avg       0.60      0.55      0.56      2590\n",
      "weighted avg       0.62      0.59      0.60      2590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/com/miniconda2/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "# f1_score(y_test, y_pred, average='macro')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb006599-579c-4d23-b2d5-1a5f44db8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = LogisticRegression(random_state=0)\n",
    "cross_val_score(clf, X_test, y_test, cv=10, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa003adb-ee7c-4451-a84f-8fcd9034b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/home/com/burvec/embeddings/'\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "embs = [mypath+f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86926be4-29cc-4372-a950-411cb32bba98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a9c9783485a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ff341f5-7a47-47f0-9e2f-02d822b3c15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dbf2ff1-b737-4fd0-b822-803333bbb488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/com/burvec/embeddings/w2v.5.100\n",
      "0.19513901098916622\n",
      "/home/com/burvec/embeddings/svd.50\n",
      "0.14881248675266964\n",
      "/home/com/burvec/embeddings/w2v.5.500\n",
      "0.197735222537948\n",
      "/home/com/burvec/embeddings/glove.50\n",
      "0.19511088417449907\n",
      "/home/com/burvec/embeddings/svd.10.50\n",
      "0.1708918422698234\n",
      "/home/com/burvec/embeddings/glove.10.100\n",
      "0.1885979514829305\n",
      "/home/com/burvec/embeddings/w2v.2.100\n",
      "0.1968095553258362\n",
      "/home/com/burvec/embeddings/svd.100\n",
      "0.16693943288343205\n",
      "/home/com/burvec/embeddings/svd.2.50\n",
      "0.1500085821206697\n",
      "/home/com/burvec/embeddings/glove.100\n",
      "0.19758098997869325\n",
      "/home/com/burvec/embeddings/glove.10.50\n",
      "0.19551654571767157\n",
      "/home/com/burvec/embeddings/svd.2.100\n",
      "0.1578127511784426\n",
      "/home/com/burvec/embeddings/svd.10.500\n",
      "0.18947394291080652\n",
      "/home/com/burvec/embeddings/w2v.10.50\n",
      "0.19551654571767157\n",
      "/home/com/burvec/embeddings/w2v.2.50\n",
      "0.19723372541647707\n",
      "/home/com/burvec/embeddings/svd.5.500\n",
      "0.18636214399881648\n",
      "/home/com/burvec/embeddings/svd.2.500\n",
      "0.18348967752800627\n",
      "/home/com/burvec/embeddings/glove.2.100\n",
      "0.1968095553258362\n",
      "/home/com/burvec/embeddings/svd.5.50\n",
      "0.1529683809325816\n",
      "/home/com/burvec/embeddings/glove.2.500\n",
      "0.19683078036031743\n",
      "/home/com/burvec/embeddings/w2v.10.100\n",
      "0.1885979514829305\n",
      "/home/com/burvec/embeddings/glove.5.50\n",
      "0.2025412076747634\n",
      "/home/com/burvec/embeddings/w2v.10.500\n",
      "0.19119491837114205\n",
      "/home/com/burvec/embeddings/w2v.5.50\n",
      "0.2025412076747634\n",
      "/home/com/burvec/embeddings/glove.5.100\n",
      "0.19513901098916622\n",
      "/home/com/burvec/embeddings/svd.500\n",
      "0.18487005719695107\n",
      "/home/com/burvec/embeddings/glove.5.500\n",
      "0.197735222537948\n",
      "/home/com/burvec/embeddings/svd.5.100\n",
      "0.169814256821247\n",
      "/home/com/burvec/embeddings/Untitled.ipynb\n",
      "/home/com/burvec/embeddings/svd.10.100\n",
      "0.18474124180674545\n",
      "/home/com/burvec/embeddings/glove.10.500\n",
      "0.19119491837114205\n",
      "/home/com/burvec/embeddings/w2v.2.500\n",
      "0.19683078036031743\n",
      "/home/com/burvec/embeddings/glove.2.50\n",
      "0.19723372541647707\n",
      "/home/com/burvec/embeddings/vocab.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'минии'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-0724cbcced7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     clf = LogisticRegression(max_iter=200, random_state=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-650d989f39b3>\u001b[0m in \u001b[0;36mget_train\u001b[0;34m(we, vocab)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mposs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mposs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-650d989f39b3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mposs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mposs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'минии'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "for emb in embs:\n",
    "    print(emb)\n",
    "    if 'Untitled' in emb:\n",
    "        continue\n",
    "    \n",
    "    we = read_emb(emb)    \n",
    "    X_train, y_train = get_train(we, vocab)\n",
    "    X_test, y_test = get_test(we, vocab)\n",
    "#     clf = LogisticRegression(max_iter=200, random_state=0)\n",
    "    clf = SVC(C=100, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e51cd96e-dbb7-4a98-9aa0-ff9dce0b4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "65ce9eca-9923-4a3d-b42a-2fee742ba425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3567)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss(torch.tensor([0.7]),torch.tensor([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cf008385-b7c3-4a23-8922-92d8a4fe02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5334, -0.2985,  1.5134], requires_grad=True)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ed8872c-74eb-469b-b50c-e3f4acdd57d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3).random_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b4a9a596-1dd1-4224-9c97-97ec4e02150a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b189b8b-f764-488b-98e5-ead1b10fe4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "numpy.intersect1d(['a'],['a','b'],['c']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "84db1ae5-aee7-419b-b689-891affe3fcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89cfb82-ee2e-48d1-9279-30934b6e254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = vocab[0]\n",
    "for vec in vocab:\n",
    "    print(len(vec))\n",
    "    total = numpy.intersect1d(total, vec).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82013d19-cb37-4e75-a334-5274e4c8f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c8567-0f23-489c-b92e-2f3f3ff0351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0b39db-71a3-4369-b717-123419ed82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "# a = [[1,2,3],[4,5,6]]\n",
    "# write\n",
    "# Path(\"vocab.json\").write_text(json.dumps(toal))\n",
    "# read\n",
    "# json.loads(Path(\"file.json\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a77180e-68e6-45ed-8969-714ed1720e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.loads(Path(\"vocab.json\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5f6fd38-e0f1-49a1-851a-f200bdd1e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hадаhад'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b72aeb-2e80-451e-bdd4-8aa6cd65d431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
