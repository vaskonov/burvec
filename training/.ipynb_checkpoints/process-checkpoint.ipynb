{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from composes.semantic_space.space import Space\n",
    "from composes.transformation.scaling.ppmi_weighting import PpmiWeighting\n",
    "from composes.matrix.sparse_matrix import SparseMatrix\n",
    "from composes.similarity.cos import CosSimilarity\n",
    "\n",
    "data = './pmi/'+linkage+'.'+str(th)+'.data'\n",
    "rows = './pmi/'+linkage+'.'+str(th)+'.rows'\n",
    "cols = './pmi/'+linkage+'.'+str(th)+'.cols'\n",
    "\n",
    "my_space = Space.build(data = data, rows = rows, cols = cols, format = \"sm\")\n",
    "print(\"loaded\")\n",
    "\n",
    "my_space = my_space.apply(PpmiWeighting())\n",
    "print(\"pmied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print my_space.function_space.get_sim(\"good_function\", \"good_function\", CosSimilarity())\n",
    "# print my_space.id2row\n",
    "\n",
    "#compute similarity between two words in the space \n",
    "# print my_space.get_sim(\"гэр\", \"\", CosSimilarity())\n",
    "words = ns.get_neighbours(\"уралиг\", 30, CosSimilarity())\n",
    "\n",
    "# тамир(спорт) - спорт\n",
    "\n",
    "# восточный гороскоп\n",
    "# бишэн\n",
    "\n",
    "# разновидности дацанов\n",
    "# дасан\n",
    "\n",
    "# улас - страны\n",
    "\n",
    "# similarity\n",
    "\n",
    "# шажан - христаой\n",
    "\n",
    "for word in words:\n",
    "    print(word[0])\n",
    "    print(word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print ns.get_sim(\"соёл\", \"хүгжэм\", CosSimilarity())\n",
    "# print ns.get_sim(\"соёл\", \"католицизм\", CosSimilarity())\n",
    "\n",
    "# print ns.get_sim(\"бүлэ\", \"аба\", CosSimilarity())\n",
    "# print ns.get_sim(\"бүлэ\", \"эжи\", CosSimilarity())\n",
    "\n",
    "# get_sim and neibo same function\n",
    "\n",
    "print ns.get_sim(\"уралиг\", \"соёл\", CosSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import *\n",
    "from scipy.spatial.distance import *\n",
    "\n",
    "euclidean([1,0,1], [1,0.1,0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "evaludict = OrderedDict({\n",
    "'бүлэ': ['эжи', 'аба', 'баабай', 'ахай', 'абга', 'абгай', 'хүүгэд', 'айл', 'эзэн', 'түрэл'],\n",
    "'улас': ['гүрэн', 'орон', 'аймаг', 'хотон'],\n",
    "'мүрэн': ['нил', 'онон', 'волга', 'лена'],\n",
    "'хэлэн': ['ород', 'буряад', 'монгол', 'хитад'], #хариин\n",
    "'шажан': ['католицизм', 'ламын', 'мүргэл', 'үргэл'], #бөөгэй буддын\n",
    "'хада': ['саяан', 'гималаа', 'хабсагай', 'уула', 'гүбээ'],\n",
    "'ухаан': ['геометри', 'физикэ', 'хими', 'биологи', 'эрдэм', 'мэдэсэ'],\n",
    "'едеэн': ['хилээмэн', 'мяхан', 'хартаабха', 'тоһон', 'талхан', 'бообо', 'эреэлжэ', 'хошхоног', 'аарсан'],\n",
    "'ундан': ['һүн', 'сай', 'архи', 'уһан', 'шүүһэн', 'уураг', 'тараг'],\n",
    "'мал': ['хонин', 'ухэр', 'гахай', 'морин', 'тэмээн', 'ямаан'],\n",
    "'хубсаһан': ['дэгэл', 'малгай', 'бээлэй', 'умдэн', 'тэрлиг', 'самса', 'гутал', 'пупайха', 'оймһон', 'уужа'],\n",
    "'жэмэс': ['нэрһэн', 'мойһон', 'улир', 'долоогоно'],\n",
    "'амһарта': ['табаг', 'һаба', 'тогоон', 'халбага', 'һэрээ', 'хүнэг', 'аяга'],\n",
    "'сэсэг': ['улаалзай', 'ургы', 'тэрэнги'],\n",
    "'шубуун': ['элеэ', 'хараасгай', 'борбилоо', 'гулабхаа', 'шаазгай', 'бүбөөлжэн', 'булжамуур', 'бэгсэргэ'],\n",
    "'үе': ['намар', 'хабар', 'үбэл', 'зун'],\n",
    "'нюур':  ['нюдэн', 'хасар', 'үрүүн', 'урал', 'сохо'],\n",
    "'бэе': ['хүл', 'гар', 'нюрган', 'үбсүүн', 'сээжэ', 'гэдэһэн'],\n",
    "'саһан': ['бороон', 'һалхин', 'шүүдэр', 'манан', 'мүндэр', 'хюруу', 'аадар'],\n",
    "'үнгэ': ['сагаан', 'хара', 'боро', 'улаан', 'ногоон', 'шара', 'хүхэ'],\n",
    "'бүд' : ['торгон', 'нооһон', 'хилэн', 'арhан'],\n",
    "'зохёол': ['шүлэг', 'таабари', 'поэмэ', 'үльгэр', 'магтаал'],#онтохон\n",
    "'гэр': ['үүдэн', 'сонхо', 'хана', 'хушалта', 'гэшхүүр'], #богоһо\n",
    "'яһан': ['hγγжэ', 'шагай', 'хабирга', 'һээр', 'дала', 'хабһан'],\n",
    "'зүрхэн': ['уушхан', 'эльгэн', 'бөөрэ', 'гүзээн', 'дэлюун']\n",
    "})\n",
    "\n",
    "# Ан: амитан, туулай, шоно, баабгай, үнэгэн, булган, хэрмэн, гүрөөһэн, арсалан, заан, һармагшан\n",
    "# 'дархалалга': ['тэргэ','ханза'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ухэр, улаалзай, едеэн - not in the text\n",
    "# шүүһэн, хубсаһан, волга - to check\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from composes.matrix.dense_matrix import DenseMatrix\n",
    "from composes.similarity.cos import CosSimilarity\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from numpy.linalg import norm\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "def score(model, evalu, vocab, eval_func):\n",
    "    \n",
    "#     model_pred = []\n",
    "#     model_gold = []\n",
    "    \n",
    "#     no_keys = []\n",
    "#     no_values = []\n",
    "\n",
    "    no_here = []\n",
    "    scores = OrderedDict({})\n",
    "\n",
    "#     vocab = ns.id2row\n",
    "#     print('vocab size:', len(vocab))\n",
    "\n",
    "    for key, values in evalu.items():\n",
    "        \n",
    "        \n",
    "        for value in values:\n",
    "            \n",
    "            if value not in vocab:\n",
    "                no_here.append(value)\n",
    "                continue\n",
    "            \n",
    "            if key not in vocab:\n",
    "                no_here.append(key)\n",
    "                continue\n",
    "            \n",
    "#             if (key in vocab) and (value in vocab):\n",
    "            \n",
    "#             scores[(key, value)] = (ns.get_sim(key, value, CosSimilarity()), 1)\n",
    "            scores[(key, value)] = (eval_func(model, key, value), 1)\n",
    "            \n",
    "            \n",
    "#                 model_pred.append(ns.get_sim(key, value, CosSimilarity()))\n",
    "#                 model_gold.append(1)\n",
    "#             else:\n",
    "#                 model_pred.append(0)\n",
    "#                 model_gold.append(1)\n",
    "\n",
    "\n",
    "    eval_values = evalu.values()\n",
    "    for idx, key in enumerate(evalu.keys()):\n",
    "        if idx+1<len(eval_values):\n",
    "            for value in eval_values[idx+1]:\n",
    "                if key not in no_here and value not in no_here:\n",
    "            \n",
    "#                 if (key in vocab) and (value in vocab):\n",
    "#                     scores[(key, value)] = (ns.get_sim(key, value, CosSimilarity()), 0)\n",
    "                    scores[(key, value)] = (eval_func(model, key, value), 0)\n",
    "            \n",
    "#                     no_here.append((key, value))\n",
    "    \n",
    "#                     model_pred.append(ns.get_sim(key, value, CosSimilarity()))\n",
    "#                     model_gold.append(0)\n",
    "#                 else:\n",
    "#                     model_pred.append(1)\n",
    "#                     model_gold.append(0)\n",
    "\n",
    "#     \n",
    "#     print(\" \".join(list(set(no_keys))))\n",
    "#     print(\" \".join(list(set(no_values))))\n",
    "\n",
    "#     return no_keys, no_values, euclidean(model_pred, model_gold)\n",
    "#     return no_keys, no_values, scores\n",
    "    return no_here, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "print norm([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for key, values in evalu.items():\n",
    "#     print(key)\n",
    "    \n",
    "#     if key in ns.row2id:\n",
    "#         keym = DenseMatrix(ns.get_row(key)).get_mat()\n",
    "#         keyl = numpy.array(keym)[0].tolist()\n",
    "        \n",
    "#         print(norm(keyl))\n",
    "#         sys.exit(0)\n",
    "\n",
    "#         for value in values:\n",
    "#             if value in ns.row2id:\n",
    "#                 print(key)\n",
    "#                 print(value)\n",
    "        \n",
    "#                 valuem = DenseMatrix(ns.get_row(value)).get_mat()\n",
    "#                 valuel = numpy.array(valuem)[0].tolist()\n",
    "#                 print cosine(keyl, valuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(linkage, th):\n",
    "    data = './pmi/'+linkage+'-'+str(th)+'-data'\n",
    "    rows = './pmi/'+linkage+'-'+str(th)+'-rows'\n",
    "    cols = './pmi/'+linkage+'-'+str(th)+'-cols'\n",
    "\n",
    "    my_space = Space.build(data = data, rows = rows, cols = cols, format = \"sm\")\n",
    "    my_space = my_space.apply(PpmiWeighting())\n",
    "    return my_space\n",
    "\n",
    "#my_space = my_space.apply(Svd(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def svd(space, dim):\n",
    "    svdm = TruncatedSVD(n_components=dim, random_state=42)\n",
    "    B = svdm.fit_transform(space.cooccurrence_matrix.mat)\n",
    "    return Space(SparseMatrix(B), list(space.id2row), [],\n",
    "                     space.row2id.copy(), {}, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from composes.transformation.dim_reduction.svd import Svd\n",
    "from composes.semantic_space.space import Space\n",
    "from composes.transformation.scaling.ppmi_weighting import PpmiWeighting\n",
    "from composes.matrix.sparse_matrix import SparseMatrix\n",
    "from composes.similarity.cos import CosSimilarity\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "scores = OrderedDict({})\n",
    "\n",
    "space_zero = load_model('none', 0)\n",
    "# space_zero = svd(space_zero, 500)\n",
    "# def_no_keys, def_no_values, def_score = score(space_zero, evaludict)\n",
    "no_here, def_score = score(space_zero, evaludict, space_zero.id2row)\n",
    "# print('score:', def_score)\n",
    "\n",
    "scores[('none', 0)] = def_score\n",
    "linkages = ['average', 'complete']\n",
    "\n",
    "for linkage in linkages:\n",
    "    \n",
    "    for th in np.arange(0.5,1.5,0.1):\n",
    "        print(linkage, th)\n",
    "        space = load_model(linkage, th)\n",
    "#         space = svd(space, 500)\n",
    "#         no_keys, no_values, scoren = score(space, evaludict)\n",
    "        no_here, scoren = score(space, evaludict, space.id2row, pmisim)\n",
    "        scores[(linkage, th)] = scoren\n",
    "        \n",
    "#         if set(no_keys) == set(def_no_keys) and set(no_values) == set(def_no_values):\n",
    "#             print('LINKAGE:', linkage, 'th:', th, 'score:', scoren)\n",
    "#         else:\n",
    "#             print(scoren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "word_pairs = [value.keys() for value in scores.values()]\n",
    "word_pairs_int = reduce(set.intersection, map(set, word_pairs))\n",
    "\n",
    "print('the num of none pairs:', len(scores[('none',0)].keys()))\n",
    "print('the num of intersection pairs:', len(word_pairs_int))\n",
    "\n",
    "scores_reduced = scores.copy()\n",
    "for key, value in scores_reduced.iteritems():\n",
    "    scores_reduced[key] = { pair: value[pair] for pair in word_pairs_int }\n",
    "    \n",
    "print('the reduced num of none pairs:', len(scores_reduced[('none',0)].keys()))\n",
    "\n",
    "for system, pairs in scores_reduced.iteritems():\n",
    "    pred = [el[0] for el in pairs.values()]\n",
    "    gold = [el[1] for el in pairs.values()]\n",
    "    print(system)\n",
    "    print(euclidean(pred, gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "max_length = 0\n",
    "with open('bur_text.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        max_length = max(max_length, len(line))\n",
    "    \n",
    "params = {'size': 100, 'window': 5, 'min_count': 10, 'sample': 1e-3, 'workers': max(1, multiprocessing.cpu_count() - 1)}\n",
    "word2vec = Word2Vec(LineSentence('bur_text.txt', max_sentence_length=max_length), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(word2vec.wv.similarity(u'бүлэ', u'аба'))\n",
    "# print(ns.get_sim('аба', 'бүлэ', CosSimilarity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "def w2vsim(word2vec, word1, word2):\n",
    "    return (word2vec.wv.similarity(word1.decode('utf-8'), word2.decode('utf-8')))\n",
    "\n",
    "def pmisim(ns, word1, word2):\n",
    "    return ns.get_sim('аба', 'бүлэ', CosSimilarity())\n",
    "\n",
    "print(w2vsim(word2vec,'аба', 'бүлэ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'аба'.decode('utf-8') in word2vec.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space = load_model('average', 1.5)\n",
    "space = svd(space, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = space.get_neighbours(\"дасан\", 30, CosSimilarity())\n",
    "\n",
    "# space.\n",
    "\n",
    "# тамир(спорт) - спорт\n",
    "\n",
    "# восточный гороскоп\n",
    "# бишэн - обезьяна\n",
    "\n",
    "# разновидности дацанов\n",
    "# дасан\n",
    "\n",
    "# улас - страны\n",
    "\n",
    "# similarity\n",
    "\n",
    "# шажан - христаой\n",
    "\n",
    "for word in words:\n",
    "    print(word[0])\n",
    "    print(word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space.export(file_prefix='exp', format=\"dm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
